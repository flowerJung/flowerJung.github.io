{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "700afb53",
   "metadata": {},
   "source": [
    "# (2) load_wine : 와인 분류\n",
    "\n",
    "## 1 필요한 모듈 import하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6b544fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e939780b",
   "metadata": {},
   "source": [
    "## 2  데이터 준비 - load_wine 메서드를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "36bb9ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'frame', 'target', 'target_names']\n"
     ]
    }
   ],
   "source": [
    "wine = load_wine()\n",
    "\n",
    "print(dir(wine))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845b63ab",
   "metadata": {},
   "source": [
    "## 3 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e2723f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine_data의 배열구조:  (178, 13)\n",
      "wine_label의 배열구조: (178,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터와 타겟의 이름을 재정의하고 배열 구조 확인\n",
    "wine_data = wine.data\n",
    "wine_label = wine.target\n",
    "\n",
    "print(\"wine_data의 배열구조: \", wine_data.shape)\n",
    "print(\"wine_label의 배열구조:\", wine_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b9953e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타겟 이름 확인: ['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n"
     ]
    }
   ],
   "source": [
    "# 특성 이름 확인하기\n",
    "print(\"타겟 이름 확인:\", wine.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1fa7b657",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타겟 이름 확인: ['class_0' 'class_1' 'class_2']\n"
     ]
    }
   ],
   "source": [
    "# 타겟 이름 확인하기\n",
    "print(\"타겟 이름 확인:\", wine.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "dfafc919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 Describe 해 보기\n",
    "print(wine.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364f95a3",
   "metadata": {},
   "source": [
    "## 4 train, test 데이터 분리 - train_test_split()이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "50c39a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수 : 142 , X_test 개수 : 36\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(wine_data, wine_label,test_size=0.2, random_state=42)\n",
    "\n",
    "print('X_train 개수 :', len(X_train),', X_test 개수 :', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1e8550ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 배열구조 : (142, 13)    y_train 배열구조 : (142,)\n",
      "X_test 배열구조 : (36, 13)    y_test 배열구조 : (36,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train 배열구조 :\", X_train.shape, \"   y_train 배열구조 :\", y_train.shape)\n",
    "print(\"X_test 배열구조 :\", X_test.shape, \"   y_test 배열구조 :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fd9052",
   "metadata": {},
   "source": [
    "## 5 다양한 모델로 학습시켜보기\n",
    "- Decision Tree 사용해 보기\n",
    "- Random Forest 사용해 보기\n",
    "- SVM 사용해 보기\n",
    "- SGD Classifier 사용해 보기\n",
    "- Logistic Regression 사용해 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677213ac",
   "metadata": {},
   "source": [
    "### Decision Tree 모델로 학습, 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e4f943ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree 모델의 정확도 : 0.9444444444444444 \n",
      "\n",
      "Decision Tree 모델의 분류 성능표 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        14\n",
      "           1       0.93      1.00      0.97        14\n",
      "           2       1.00      0.88      0.93         8\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.95      0.93      0.94        36\n",
      "weighted avg       0.95      0.94      0.94        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Decision Tree 모델 만들기\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "\n",
    "# Decision Tree 모델로 훈련\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터의 예상값 저장\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# 모델 정확도 알아보기1\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Decision Tree 모델의 정확도 :\", accuracy, \"\\n\")\n",
    "\n",
    "# 모델 분류 성능표\n",
    "print(\"Decision Tree 모델의 분류 성능표 \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234799cf",
   "metadata": {},
   "source": [
    "### Random Forest 모델로 학습, 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ba44959b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest 모델의 정확도 : 1.0 \n",
      "\n",
      "RandomForest 모델의 분류 성능표 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# RandomForestClassifier 모델 생성\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "\n",
    "# RandomForestClassifier 모델 훈련\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터의 예상값 저장\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# 모델 정확도 알아보기\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"RandomForest 모델의 정확도 :\", accuracy, \"\\n\")\n",
    "\n",
    "# 모델 분류 성능표\n",
    "print(\"RandomForest 모델의 분류 성능표 \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa3907c",
   "metadata": {},
   "source": [
    "### SVM 모델로 학습, 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "61da8c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 모델의 정확도 : 0.8055555555555556 \n",
      "\n",
      "SVM 모델의 분류 성능표 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.73      0.79      0.76        14\n",
      "           2       0.57      0.50      0.53         8\n",
      "\n",
      "    accuracy                           0.81        36\n",
      "   macro avg       0.77      0.76      0.76        36\n",
      "weighted avg       0.80      0.81      0.80        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# SVM 모델 생성\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "# SVM 모델 훈련\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터의 예상값 저장\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# 모델 정확도 알아보기\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"SVM 모델의 정확도 :\", accuracy, \"\\n\")\n",
    "\n",
    "## 모델 분류 성능표\n",
    "print(\"SVM 모델의 분류 성능표 \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b0737a",
   "metadata": {},
   "source": [
    "### SGD Classifier 모델로 학습, 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6a91099e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD 모델의 정확도 : 0.6944444444444444 \n",
      "\n",
      "SGD 모델의 분류 성능표 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.79      0.88        14\n",
      "           1       0.56      1.00      0.72        14\n",
      "           2       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.69        36\n",
      "   macro avg       0.52      0.60      0.53        36\n",
      "weighted avg       0.61      0.69      0.62        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# SGD 모델 생성\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "# SGD 모델 훈련\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터의 예상값 저장\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "# 모델 정확도 알아보기\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"SGD 모델의 정확도 :\", accuracy, \"\\n\")\n",
    "\n",
    "# 모델 분류 성능표\n",
    "print(\"SGD 모델의 분류 성능표 \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab90106",
   "metadata": {},
   "source": [
    "#### 빨간 경고문이 뜨넹요...\n",
    "경고문이 나온다는 것은 무엇이 좋지 않다는 이야기인데..<br>\n",
    "그래서 번역기를 돌렸더니 오차행렬에서 0이 있어서 계산은 하지만<br>\n",
    "경고문을 보내니 'zero_division'의 파라미터를 조정하라고 하네요..<br>\n",
    "'zero_division'의 기본값은 'warn', 0을 받아는 주지만 경고문은 발송하는 거라고...<br>\n",
    "그래서 어디서 0이 나오는 지 확인하려고 아래에서 정답지와 예측값을 출력해보니<br>\n",
    "예측값에 2가 없네요...<br>\n",
    "데이터 개수가 적어서 그런거겠죠??<br>\n",
    "그리고 'zero_division' 파라미터는 어디서 조정해야 하는 지...<br>\n",
    "모델 생성할 때 지정하니 타입에러가 나더군요..<br>\n",
    "어디서 'zero_division'를 조정해야 할까요??<br>\n",
    "알 수 없어서 주저리 했어요..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e4d678ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 2 0 1 0 1 2 1 2 0 2 0 1 0 1 1 1 0 1 0 1 1 2 2 2 1 1 1 0 0 1 2 0 0 0]\n",
      "[1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "02ac944b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD 모델의 정확도 : 0.6111111111111112 \n",
      "\n",
      "SGD 모델의 분류 성능표 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      1.00      0.70        14\n",
      "           1       0.86      0.43      0.57        14\n",
      "           2       0.67      0.25      0.36         8\n",
      "\n",
      "    accuracy                           0.61        36\n",
      "   macro avg       0.69      0.56      0.55        36\n",
      "weighted avg       0.69      0.61      0.58        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SGD 모델 생성\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "# SGD 모델 훈련\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터의 예상값 저장\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "# 모델 정확도 알아보기\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"SGD 모델의 정확도 :\", accuracy, \"\\n\")\n",
    "\n",
    "# 모델 분류 성능표\n",
    "print(\"SGD 모델의 분류 성능표 \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfb138a",
   "metadata": {},
   "source": [
    "#### 근데 위에서는 되네요... \n",
    "이건 데이터 부족일까요?? 모델 불안정일까요??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ff25ba",
   "metadata": {},
   "source": [
    "### Logistic Regression 모델로 학습, 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "00d13ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 모델의 정확도 : 0.9722222222222222 \n",
      "\n",
      "Logistic Regression 모델의 분류 성능표 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96        14\n",
      "           1       0.93      1.00      0.97        14\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.98      0.98      0.98        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Logistic Regression 모델 훈련\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터의 예상값 저장\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# 모델 정확도 알아보기\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression 모델의 정확도 :\", accuracy, \"\\n\")\n",
    "\n",
    "# 모델 분류 성능표\n",
    "print(\"Logistic Regression 모델의 분류 성능표 \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e9257a",
   "metadata": {},
   "source": [
    "#### Logistic Regression 모델 훈련 후 평가를 했더니 빨간 경고문이 뜬다.\n",
    " 경고문이 싫어서 번역을 해 보았더니 max_iter를 늘이거나 데이터 크기를 조정하라고 하네요..<br>\n",
    " 주어진 데이터이니 데이터 크기를 조정할 수 없어 <br>\n",
    " 'max_iter' 하이퍼파라미터를 조정했습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6c7f3ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 모델의 정확도 : 1.0 \n",
      "\n",
      "Logistic Regression 모델의 분류 성능표 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       1.00      1.00      1.00        14\n",
      "           2       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter = 2900)\n",
    "\n",
    "# Logistic Regression 모델 훈련\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터의 예상값 저장\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# 모델 정확도 알아보기\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression 모델의 정확도 :\", accuracy, \"\\n\")\n",
    "\n",
    "# 모델 분류 성능표\n",
    "print(\"Logistic Regression 모델의 분류 성능표 \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49022fd",
   "metadata": {},
   "source": [
    "##  6 모델평가하기\n",
    "\n",
    "### 와인 분류에서는 \n",
    "정확도와 모델 분류 성능표가 RandonForest, Logistic Regression 둘 다 1이 나와서 고민을 했습니다.<br>\n",
    "RandonForest는 하이퍼파라미터를 조정하지 않아도 1이 나오고, <br>\n",
    "Logistic Regression은 하이퍼파라미터 'max_iter'를 조정하고 나서 1이 나왔으므로<br>\n",
    "RandonForest모델이 더 적합하다고 생각됩니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
