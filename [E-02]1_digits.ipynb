{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b349f23",
   "metadata": {},
   "source": [
    "# (1) load_digits : 손글씨를 분류\n",
    "\n",
    "## 1 필요한 모듈 import하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0dab2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914f7466",
   "metadata": {},
   "source": [
    "## 2  데이터 준비 - load_digits 메서드를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ed34556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DESCR', 'data', 'feature_names', 'frame', 'images', 'target', 'target_names']\n"
     ]
    }
   ],
   "source": [
    "digits = load_digits()\n",
    "\n",
    "print(dir(digits))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bc923b",
   "metadata": {},
   "source": [
    "## 3 데이터 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34e41bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digits_data의 배열구조:  (1797, 64)\n",
      "digits_label의 배열구조: (1797,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터와 타겟의 이름을 재정의하고 배열 구조 확인\n",
    "digits_data = digits.data\n",
    "digits_label = digits.target\n",
    "\n",
    "print(\"digits_data의 배열구조: \", digits_data.shape)\n",
    "print(\"digits_label의 배열구조:\", digits_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa263eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타겟 이름 확인: ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n"
     ]
    }
   ],
   "source": [
    "# 특성 이름 확인하기\n",
    "print(\"타겟 이름 확인:\", digits.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "513f223f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타겟 이름 확인: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# 타겟 이름 확인하기\n",
    "print(\"타겟 이름 확인:\", digits.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d18eeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터 Describe 해 보기\n",
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7293bfb6",
   "metadata": {},
   "source": [
    "## 4 train, test 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aa24ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 개수 : 1437 , X_test 개수 : 360\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits_data, digits_label,test_size=0.2, random_state=7)\n",
    "\n",
    "print('X_train 개수 :', len(X_train),', X_test 개수 :', len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d0637bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train 배열구조 : (1437, 64)    y_train 배열구조 : (1437,)\n",
      "X_test 배열구조 : (360, 64)    y_test 배열구조 : (360,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train 배열구조 :\", X_train.shape, \"   y_train 배열구조 :\", y_train.shape)\n",
    "print(\"X_test 배열구조 :\", X_test.shape, \"   y_test 배열구조 :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde8533e",
   "metadata": {},
   "source": [
    "## 다양한 모델로 학습시켜보기\n",
    "- Decision Tree 사용해 보기\n",
    "- Random Forest 사용해 보기\n",
    "- SVM 사용해 보기\n",
    "- SGD Classifier 사용해 보기\n",
    "- Logistic Regression 사용해 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fd2c3b",
   "metadata": {},
   "source": [
    "### Decision Tree 모델로 학습, 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a9a20e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree 모델의 정확도 : 0.8555555555555555 \n",
      "\n",
      "Decision Tree 모델의 분류 성능표 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.81      0.81      0.81        42\n",
      "           2       0.79      0.82      0.80        40\n",
      "           3       0.79      0.91      0.85        34\n",
      "           4       0.83      0.95      0.89        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       0.84      0.93      0.88        28\n",
      "           7       0.96      0.82      0.89        33\n",
      "           8       0.88      0.65      0.75        43\n",
      "           9       0.78      0.78      0.78        32\n",
      "\n",
      "    accuracy                           0.86       360\n",
      "   macro avg       0.86      0.86      0.86       360\n",
      "weighted avg       0.86      0.86      0.85       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Decision Tree 모델 만들기\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "\n",
    "# Decision Tree 모델로 훈련\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터의 예상값 저장\n",
    "y_pred = decision_tree.predict(X_test)\n",
    "\n",
    "# 모델 정확도 알아보기1\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Decision Tree 모델의 정확도 :\", accuracy, \"\\n\")\n",
    "\n",
    "# 모델 분류 성능표\n",
    "print(\"Decision Tree 모델의 분류 성능표 \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081b9cb0",
   "metadata": {},
   "source": [
    "### Random Forest 모델로 학습, 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "038fa66d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest 모델의 정확도 : 0.9638888888888889 \n",
      "\n",
      "RandomForest 모델의 분류 성능표 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        43\n",
      "           1       0.93      1.00      0.97        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       0.93      1.00      0.96        37\n",
      "           5       0.90      0.96      0.93        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       1.00      0.84      0.91        43\n",
      "           9       0.94      0.94      0.94        32\n",
      "\n",
      "    accuracy                           0.96       360\n",
      "   macro avg       0.96      0.96      0.96       360\n",
      "weighted avg       0.97      0.96      0.96       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# RandomForestClassifier 모델 생성\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "\n",
    "# RandomForestClassifier 모델 훈련\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터의 예상값 저장\n",
    "y_pred = random_forest.predict(X_test)\n",
    "\n",
    "# 모델 정확도 알아보기\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"RandomForest 모델의 정확도 :\", accuracy, \"\\n\")\n",
    "\n",
    "# 모델 분류 성능표\n",
    "print(\"RandomForest 모델의 분류 성능표 \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1c14c4",
   "metadata": {},
   "source": [
    "### SVM 모델로 학습, 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8a34bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM 모델의 정확도 : 0.9888888888888889 \n",
      "\n",
      "SVM 모델의 분류 성능표 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      1.00      0.98        42\n",
      "           2       1.00      1.00      1.00        40\n",
      "           3       1.00      1.00      1.00        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       1.00      1.00      1.00        28\n",
      "           7       1.00      1.00      1.00        33\n",
      "           8       1.00      0.93      0.96        43\n",
      "           9       1.00      0.97      0.98        32\n",
      "\n",
      "    accuracy                           0.99       360\n",
      "   macro avg       0.99      0.99      0.99       360\n",
      "weighted avg       0.99      0.99      0.99       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# SVM 모델 생성\n",
    "svm_model = svm.SVC()\n",
    "\n",
    "# SVM 모델 훈련\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터의 예상값 저장\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "# 모델 정확도 알아보기\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"SVM 모델의 정확도 :\", accuracy, \"\\n\")\n",
    "\n",
    "## 모델 분류 성능표\n",
    "print(\"SVM 모델의 분류 성능표 \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e73e1f",
   "metadata": {},
   "source": [
    "### SGD Classifier 모델로 학습, 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4c1c18e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD 모델의 정확도 : 0.95 \n",
      "\n",
      "SGD 모델의 분류 성능표 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.84      0.90      0.87        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.92      0.97      0.94        34\n",
      "           4       1.00      0.97      0.99        37\n",
      "           5       0.93      1.00      0.97        28\n",
      "           6       0.96      0.93      0.95        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.97      0.86      0.91        43\n",
      "           9       0.94      0.91      0.92        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# SGD 모델 생성\n",
    "sgd_model = SGDClassifier()\n",
    "\n",
    "# SGD 모델 훈련\n",
    "sgd_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터의 예상값 저장\n",
    "y_pred = sgd_model.predict(X_test)\n",
    "\n",
    "# 모델 정확도 알아보기\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"SGD 모델의 정확도 :\", accuracy, \"\\n\")\n",
    "\n",
    "# 모델 분류 성능표\n",
    "print(\"SGD 모델의 분류 성능표 \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc892a2",
   "metadata": {},
   "source": [
    "### Logistic Regression 모델로 학습, 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "375fa38b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 모델의 정확도 : 0.9527777777777777 \n",
      "\n",
      "Logistic Regression 모델의 분류 성능표 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      0.95      0.95        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.97      0.96        34\n",
      "           4       0.97      1.00      0.99        37\n",
      "           5       0.82      0.96      0.89        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.97      0.97      0.97        33\n",
      "           8       0.92      0.81      0.86        43\n",
      "           9       0.97      0.91      0.94        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression()\n",
    "\n",
    "# Logistic Regression 모델 훈련\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터의 예상값 저장\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# 모델 정확도 알아보기\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression 모델의 정확도 :\", accuracy, \"\\n\")\n",
    "\n",
    "# 모델 분류 성능표\n",
    "print(\"Logistic Regression 모델의 분류 성능표 \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5353e12d",
   "metadata": {},
   "source": [
    "#### Logistic Regression 모델 훈련 후 평가를 했더니 빨간 경고문이 뜬다.\n",
    " 경고문이 싫어서 번역을 해 보았더니 max_iter를 늘이거나 데이터 크기를 조정하라고 하네요..<br>\n",
    " 주어진 데이터이니 데이터 크기를 조정할 수 없어 <br>\n",
    " 'max_iter' 하이퍼파라미터를 조정했습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca33036",
   "metadata": {},
   "source": [
    "### Logistic Regression 모델로 학습, 평가하기2 - max_iter 변화주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21e4c610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 모델의 정확도 : 0.95 \n",
      "\n",
      "Logistic Regression 모델의 분류 성능표 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        43\n",
      "           1       0.95      0.95      0.95        42\n",
      "           2       0.98      1.00      0.99        40\n",
      "           3       0.94      0.97      0.96        34\n",
      "           4       1.00      1.00      1.00        37\n",
      "           5       0.79      0.96      0.87        28\n",
      "           6       1.00      0.96      0.98        28\n",
      "           7       0.94      0.97      0.96        33\n",
      "           8       0.92      0.81      0.86        43\n",
      "           9       0.97      0.88      0.92        32\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic_model = LogisticRegression(max_iter=2100)\n",
    "\n",
    "# Logistic Regression 모델 훈련\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 데이터의 예상값 저장\n",
    "y_pred = logistic_model.predict(X_test)\n",
    "\n",
    "# 모델 정확도 알아보기\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Logistic Regression 모델의 정확도 :\", accuracy, \"\\n\")\n",
    "\n",
    "# 모델 분류 성능표\n",
    "print(\"Logistic Regression 모델의 분류 성능표 \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9b6b00",
   "metadata": {},
   "source": [
    "##  6 모델평가하기\n",
    "\n",
    "### 숫자 분류에서는 \n",
    "모델 분류 성능표가 어디 값이 좋은 지 판단할 수 없어서 **정확도로 기준**을 정했습니다.<br>\n",
    "**SVM의 정확도**가 **0.99**라서 **SVM모델이 좋다**고 판단했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf36320",
   "metadata": {},
   "source": [
    "## 회고\n",
    "- 이번 프로젝트에서 **어려웠던 점,**\n",
    "   - 훈련 모델을 쓰는 데, 어디에서 import해야 하는 지 몰라서..어려웠습니다.\n",
    "   - 정리된 데이터셋이어서 나름 편하게 한 것 같아요<br><br>\n",
    "   \n",
    "- 프로젝트를 진행하면서 **알아낸 점** 혹은 **아직 모호한 점**.\n",
    "   - **알아낸 점**\n",
    "      - 모델을 평가할 때 '**정확도**만 **중요한** 것이 아니라 오차행렬처럼 **다른 것**도 살펴야 한다'는 것\n",
    "      - classification_report에서 precision, recall, f1-score는 어떤 의미인지 알게 되었습니다.\n",
    "      - 경고문이 뜨면 번역해서 찾아내기 시도하고 성공도 하고 실패도 하고 했습니다.<br><br>\n",
    "   - **아직 모호한 점**\n",
    "      - classification_report에서 0이 생성되어 경고문이 뜨는 데, 'zero_division' 파라미터를 어디서 조정하는 지 모르겠어요<br><br>\n",
    "- 루브릭 평가 지표를 맞추기 위해 **시도한 것들**.\n",
    "   - 예제가 좋아서 별 어려움이 없었던 듯 해요..\n",
    "   - 단지 모델들의 개념을 정리하다가 아직 다 못해서.. 아쉽네요<br><br>\n",
    "- 만약에 루브릭 평가 관련 지표를 **달성 하지 못했을 때, 이유에 관한 추정**.<br><br>\n",
    "- **자기 다짐**\n",
    "   - 언제나 열심히 해서 **결과물**을 가져보는 것"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
